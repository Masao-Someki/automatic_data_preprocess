# ğŸ§™ Dataset Wizard

A CLI-based interactive assistant to help you define, configure, and implement custom datasets (e.g., Hugging Face or Lhotse) from raw files such as audio, transcription, and metadata.  
The tool guides you through a **stage-based workflow** to create high-quality, structured datasets step by step â€” with the help of an LLM (e.g., ChatGPT or Gemini).

---

## âœ¨ Features

- ğŸ“ **Automatic dataset structure analysis**
- ğŸ’¬ **LLM-powered requirement discussion**
- âœï¸ **Editable stage prompts using your `$EDITOR`**
- ğŸ§  **Smart suggestions from AI (field layout, splits, formats)**
- ğŸ› ï¸ **Code generation for dataset creation**
- ğŸ§ª **Dataset class scaffolding**
- ğŸ“¦ **Hugging Face / Lhotse support**
- ğŸ’¾ **Logs interaction history as Markdown & JSON**
- ğŸ§± **Modular stage-based architecture (easy to extend)**

---

## ğŸ Quickstart

### 1. Install the tool

```bash
git clone https://github.com/yourname/dataset-wizard.git
cd dataset-wizard
pip install -e .
````

> This registers a `dataset-wizard` command globally on your system.

---

### 2. Set your API keys

Set one or both of the following environment variables (only one is required):

```bash
export OPENAI_API_KEY=sk-...
# or
export GOOGLE_API_KEY=your-gemini-api-key
```

You can also use `.env` with `python-dotenv`.

---

### 3. Run the wizard

```bash
dataset-wizard
```

The wizard will guide you through several stages:

| Stage ID               | Purpose                                                 |
| ---------------------- | ------------------------------------------------------- |
| `analyze_dir`          | Analyze your dataset directory structure                |
| `define_dataset`       | Decide what each sample should contain (audio, text...) |
| `define_datasetdict`   | Configure splits and output path for the DatasetDict    |
| `generate_dataset`     | Generate Python code to create the dataset              |
| `define_dataset_class` | Scaffold a custom Dataset class                         |

---

## ğŸ“ Example Output

* `dataset/create_dataset.py` â€” generated dataset builder script
* `dataset/dataset.py` â€” dataset class to load your data
* `results/result.json` â€” interaction history (raw message objects)
* `results/result.md` â€” human-readable summary of the conversation

---

## ğŸ§© Project Structure

```
dataset_wizard/
â”œâ”€â”€ dataset_wizard/
â”‚   â”œâ”€â”€ cli.py              # Entry point
â”‚   â”œâ”€â”€ stages/             # All stages (e.g., analyze_dir.py)
â”‚   â”œâ”€â”€ providers/          # Provider APIs (OpenAI, Gemini, etc.)
â”‚   â””â”€â”€ utils/              # Editor, spinner, save utils, etc.
â”œâ”€â”€ prompts/                # User-facing prompts (001-*.md)
â”œâ”€â”€ resources/              # Code templates (HF/Lhotse)
â”œâ”€â”€ results/                # Saved logs (JSON + MD)
â”œâ”€â”€ setup.py
â””â”€â”€ README.md
```

---

## ğŸ§  Extending the Wizard

You can define your own stages by inheriting from `AbsStage`:

```python
class MyCustomStage(AbsStage):
    def run_body(self, provider, messages: List[dict]) -> bool:
        # implement your stage logic
        return True
```

And register them in your `cli.py`'s stage list.

---

## ğŸ—‚ï¸ Supported Dataset Backends

| Backend      | Recommended Use Case                                  |
| ------------ | ----------------------------------------------------- |
| Hugging Face | Simple segmented audio datasets with paired text      |
| Lhotse       | Long audio with segment-level extraction requirements |
| Custom       | Specify your own create\_dataset.py as a reference    |

---

## ğŸ“œ License

MIT License

---

## ğŸ™ Acknowledgements

Built with â¤ï¸ by Masao Someki, powered by OpenAI and Google Gemini.
